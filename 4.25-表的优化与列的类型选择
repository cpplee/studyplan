#复习mysql优化

列选择原则:
1:字段类型优先级 整型 > date,time > enum,char>varchar > blob
列的特点分析:
整型: 定长,没有国家/地区之分,没有字符集的差异
time定长,运算快,节省空间. 考虑时区,写sql时不方便 where > ‘2005-10-12’;
enum: 能起来约束值的目的, 内部用整型来存储,但与char联查时,内部要经历串与值的转化
Char 定长, 考虑字符集和(排序)校对集
varchar, 不定长 要考虑字符集的转换与排序时的校对集,速度慢.
text/Blob 无法使用内存临时表

附: 关于date/time的选择,大师的明确意见
http://www.xaprb.com/blog/2014/01/30/timestamps-in-mysql/


MariaDB [lush_info]> create table t3(
    -> name char(1) not null default '',
    -> key(name)
    -> )engine=myisam charset=utf8;
Query OK, 0 rows affected (0.03 sec)

MariaDB [lush_info]> create table t4(
    -> name char(1),
    -> key(name)
    -> )engine=myisam charset=utf8;
Query OK, 0 rows affected (0.00 sec)

MariaDB [lush_info]> insert into t3 values('a'),('');
Query OK, 2 rows affected (0.08 sec)
Records: 2  Duplicates: 0  Warnings: 0

MariaDB [lush_info]> insert into t4 values('a'),(null);Query OK, 2 rows affected (0.00 sec)
Records: 2  Duplicates: 0  Warnings: 0

MariaDB [lush_info]> select * from t3 where name='a';
+------+
| name |
+------+
| a    |
+------+
1 row in set (0.00 sec)



MariaDB [lush_info]> explain select * from t3 where name='a'\G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t3
         type: ref
possible_keys: name
          key: name
      key_len: 3
          ref: const
         rows: 1
        Extra: Using where; Using index
1 row in set (0.00 sec)

MariaDB [lush_info]> explain select * from t4 where name='a'\G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t4
         type: ref
possible_keys: name
          key: name
      key_len: 4
          ref: const
         rows: 1
        Extra: Using where; Using index
1 row in set (0.00 sec)

======================================================================
观察t3和t4的key_len不一样 ,用来区分null ,null占的索引空间更大(多一个字节,上万个数据就是上万个字节,查询也不方便),建表的时候不要用null,最好用not null


Enum列的说明
1: enum列在内部是用整型来储存的
2: enum列与enum列相关联速度最快
3: enum列比(var)char 的弱势---在碰到与char关联时,要转化. 要花时间.
4: 优势在于,当char非常长时,enum依然是整型固定长度.
当查询的数据量越大时,enum的优势越明显.
5: enum与char/varchar关联 ,因为要转化,速度要比enum->enum,char->char要慢,
但有时也这样用-----就是在数据量特别大时,可以节省IO.


==============================================================================================================================
1:索引类型
  1.1 B-tree索引
  注: 名叫btree索引,大的方面看,都用的平衡树,但具体的实现上, 各引擎稍有不同,
比如,严格的说,NDB引擎,使用的是T-tree
  Myisam,innodb中,默认用B-tree索引

但抽象一下---B-tree系统,可理解为”排好序的快速查找结构”.  

1.2 hash索引
     在memory表里,默认是hash索引, hash的理论查询时间复杂度为O(1)

疑问: 既然hash的查找如此高效,为什么不都用hash索引?
答: 
1:hash函数计算后的结果,是随机的,如果是在磁盘上放置数据,
比主键为id为例, 那么随着id的增长, id对应的行,在磁盘上随机放置.
2: 无法对范围查询进行优化.
3: 无法利用前缀索引. 比如 在btree中, field列的值“hellopworld”,并加索引
查询 xx=helloword,自然可以利用索引, xx=hello,也可以利用索引. (左前缀索引)
因为hash(‘helloword’),和hash(‘hello’),两者的关系仍为随机
4: 排序也无法优化.
5: 必须回行.就是说 通过索引拿到数据位置,必须回到表中取数据

=======================================================================================
 2.2 在多列上建立索引后,查询哪个列,索引都将发挥作用
误: 多列索引上,索引发挥作用,需要满足左前缀要求.
以 index(a,b,c) 为例,
语句	索引是否发挥作用
Where a=3	是,只使用了a列
Where a=3 and b=5 	是,使用了a,b列
Where a=3 and b=5 and c=4	是,使用了abc
Where b=3  /  where c=4	否
Where a=3 and c=4	a列能发挥索引,c不能
Where a=3 and b>10 and c=7	A能利用,b能利用, C不能利用
同上,where a=3 and b like ‘xxxx%’ and c=7	A能用,B能用,C不能用

 
	
为便于理解, 假设ABC各10米长的木板, 河面宽30米.
全值索引是则木板长10米,
Like,左前缀及范围查询, 则木板长6米,

自己拼接一下,能否过河对岸,就知道索引能否利用上.
如上例中, where a=3 and b>10, and c=7,
A板长10米,A列索引发挥作用
A板正常接B板, B板索引发挥作用
B板短了,接不到C板, C列的索引不发挥作用.

多列索引经典题目:
http://www.zixue.it/thread-9218-1-4.html

假设某个表有一个联合索引（c1,c2,c3,c4）一下——只能使用该联合索引的c1,c2,c3部分
A where c1=x and c2=x and c4>x and c3=x 
B where c1=x and c2=x and c4=x order by c3
C where c1=x and c4= x group by c3,c2
D where c1=x and c5=x order by c2,c3
E where c1=x and c2=x and c5=? order by c2,c3

create table t4 (
c1 tinyint(1) not null default 0,
c2 tinyint(1) not null default 0,
c3 tinyint(1) not null default 0,
c4 tinyint(1) not null default 0,
c5 tinyint(1) not null default 0,
index c1234(c1,c2,c3,c4)
);
insert into t4 values (1,3,5,6,7),(2,3,9,8,3),(4,3,2,7,5);

对于A:  *mysql在不影响语意的情况下 会给语句做优化,所以发生下面这种情况*
c1=x and c2=x and c4>x and c3=x  <==等价==> c1=x and c2=x and c3=x and c4>x
因此 c1,c2,c3,c4都能用上. 如下:
mysql> explain select * from t4 where c1=1 and c2=2 and c4>3 and c3=3 \G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t4
         type: range
possible_keys: c1234
          key: c1234
      key_len: 4 #可以看出c1,c2,c3,c4索引都用上
          ref: NULL
         rows: 1
        Extra: Using where 

对于B: select * from t4 where c1=1 and c2=2 and c4=3 order by c3  *沿着c3有序的一边查找一边验证c4,*
c1 ,c2索引用上了,在c2用到索引的基础上,c3是排好序的,因此不用额外排序.
而c4没发挥作用.
mysql> explain select * from t4 where c1=1 and c2=2 and c4=3 order by c3 \G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t4
         type: ref
possible_keys: c1234
          key: c1234
      key_len: 2
          ref: const,const
         rows: 1
        Extra: Using where
1 row in set (0.00 sec)

mysql> explain select * from t4 where c1=1 and c2=2 and c4=3 order by c5 \G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t4
         type: ref
possible_keys: c1234
          key: c1234
      key_len: 2
          ref: const,const
         rows: 1
        Extra: Using where; Using filesort
1 row in set (0.00 sec)

对于 C: 只用到c1索引,因为group by c3,c2的顺序无法利用c2,c3索引
mysql> explain select * from t4 where c1=1 and c4=2 group by c3,c2 \G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t4
         type: ref
possible_keys: c1234
          key: c1234
      key_len: 1 #只用到c1,因为先用c3后用c2分组,导致c2,c3索引没发挥作用
          ref: const
         rows: 1
        Extra: Using where; Using temporary; Using filesort
1 row in set (0.00 sec)

mysql> explain select * from t4 where c1=1 and c4=2 group by c2,c3 \G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t4
         type: ref
possible_keys: c1234
          key: c1234
      key_len: 1
          ref: const
         rows: 1
        Extra: Using where
1 row in set (0.00 sec)

D语句: C1确定的基础上,c2是有序的,C2之下C3是有序的,因此c2,c3发挥的排序的作用.
因此,没用到filesort
mysql> explain select * from t4 where c1=1 and c5=2 order by c2,c3 \G  
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t4
         type: ref
possible_keys: c1234
          key: c1234
      key_len: 1
          ref: const
         rows: 1
        Extra: Using where
1 row in set (0.00 sec)

E: 这一句等价与 elect * from t4 where c1=1 and c2=3 and c5=2 order by c3; 
因为c2的值既是固定的,参与排序时并不考虑

mysql> explain select * from t4 where c1=1 and c2=3 and c5=2 order by c2,c3 \G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t4
         type: ref
possible_keys: c1234
          key: c1234
      key_len: 2
          ref: const,const
         rows: 1
        Extra: Using where
1 row in set (0.00 sec)








==================================================================================================
myisam和innodb的索引比较(聚簇索引innodb和非聚簇索引myisam)
myisam
由索引->磁盘取数据
在这个btree中 叶子节点添加的是索引对应的物理地址 
找到数据比较快,但是回行慢
判断回行,explain执行计划,判断Extra 是否是 use index如果是 就用到了索引覆盖，效率明显的提升,只走内存的索引文件，不走回行查找，不找磁盘IO

innodb的btree上是叶子节点绑定数据,如果是聚集索引发生拆分的话,要连着数据一起移动,速度低下
innodb的主键是聚蔟索引,每一个节点带的数据比较多(比较长的列),导致沿ID查询的时候要跨过好多小文件块,
如果没有过长的char字段,差别也不会这么大



导入大量数据的时候先去掉索引(主键+其他),插入数据以后在集中更新索引,要不然速度比较慢,因为要一边插入，一边维护索引


===================================================================================================
索引的长度利用
select count(distinct left(字段,数字几位)) / count(*) from 表 
来计算比例,看取多少字节设为索引比较合适
alter table 表 add index word(word(数字几位))
1.截的越短，重复读越高，区分度越小，索引效果越不好
2.截的越长，重复度越低，索引效果越好，但是带来的影响也是越大，--增删改速度慢，并间接影响查询速度
====================================================================================================
管用手法，截取字符,测试区分度
====================================================================================================
如果字段较长,还不想截取,那就用crc转换成int类型的,这样int类型的就是4个字节 (crc函数来构造伪哈希列)
==================================================================================
大数据量下的分页

1.从业务上解决
办法:不允许翻过一定页数,例如谷歌是40,百度是70

当数据量增大的时候offset很大会很消耗时间
如果利用show profiles来看的话
找到很消耗时间的query
利用show profile for query 语句的序号
一般是Sending data耗时
2.还有一个办法 用先索引查询在去limit
但是会出现 如果删除数据 就查询不准确(但是可以记录上一次最大id)
一般解决办法是不进行物理删除,进行逻辑删除
3.延迟关联技巧 
只查索引，不查数据，得到id,
再用id去查具体条目,这种技巧就是延迟索引
第一步的时候得到的id都装在了内存里,不用一次一次的回行去表里取数据
select 表1.id,name from 表1 inner join (select id from 表1 limit 500000,10) as tmp on 表1.id=tmp.id
========================





